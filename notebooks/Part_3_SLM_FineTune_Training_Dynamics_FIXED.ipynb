{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# üöÄ SLM Fine-Tuning Part 3: Training Dynamics\n",
    "\n",
    "**What you'll learn:**\n",
    "- What loss curves tell you about training\n",
    "- How learning rate schedules affect convergence\n",
    "- How to use Weights & Biases for visualization\n",
    "- When training is working vs failing\n",
    "\n",
    "**Setup:**\n",
    "- Model: `Qwen/Qwen2.5-0.5B-Instruct`\n",
    "- Dataset: `mlabonne/guanaco-llama2-1k` (1,000 samples)\n",
    "- GPU: Colab T4 (15GB VRAM)\n",
    "- Time per run: ~10-15 minutes\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "oef8L7CXlZBX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K53gbl-5EB8b"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1Ô∏è‚É£ Setup & Installation\n",
    "\n",
    "First, let's install the required libraries."
   ],
   "metadata": {
    "id": "uKb82thplZBZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q transformers datasets peft trl accelerate bitsandbytes wandb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HagUVbVSlZBa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m532.5/532.5 kB\u001B[0m \u001B[31m27.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m59.1/59.1 MB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2Ô∏è‚É£ Weights & Biases Setup\n",
    "\n",
    "W&B will create beautiful training charts automatically.\n",
    "\n",
    "**First time?**\n",
    "1. Go to [wandb.ai](https://wandb.ai) and create a free account\n",
    "2. Run the cell below\n",
    "3. Paste your API key when prompted"
   ],
   "metadata": {
    "id": "ojnlqU1LlZBa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7-9rWgPlZBb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (1) Create a W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (2) Use an existing W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (3) Don't visualize my results\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 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\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Invalid choice\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: You chose 'Use an existing W&B account'\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find your API key here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: No netrc file found, creating one.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbalci-pelin\u001B[0m (\u001B[33mbalci-pelin-patolojiai\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3Ô∏è‚É£ Check GPU\n",
    "\n",
    "Make sure you're connected to a GPU runtime.\n",
    "\n",
    "**No GPU?** Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `T4 GPU`"
   ],
   "metadata": {
    "id": "u-7ds2RQlZBb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úÖ GPU: {gpu_name}\")\n",
    "    print(f\"‚úÖ VRAM: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected! Change runtime to GPU.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nnup_VfllZBb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ GPU: Tesla T4\n",
      "‚úÖ VRAM: 15.8 GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4Ô∏è‚É£ Configuration\n",
    "\n",
    "All settings in one place. We'll modify `LR_SCHEDULE` for each experiment."
   ],
   "metadata": {
    "id": "-d4JWZZilZBb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Model & Data\n",
    "MODEL_ID = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "DATASET_ID = \"mlabonne/guanaco-llama2-1k\"\n",
    "\n",
    "# Training Settings\n",
    "MAX_SEQ_LEN = 512\n",
    "BATCH_SIZE = 2\n",
    "GRAD_ACCUM = 8          # Effective batch = 2 * 8 = 16\n",
    "MAX_STEPS = 200         # Enough to see learning dynamics\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "# Learning Rate Schedule (we'll change this for each run)\n",
    "# Options: \"constant\", \"cosine\", \"linear\"\n",
    "LR_SCHEDULE = \"constant\"\n",
    "WARMUP_RATIO = 0.0      # We'll set to 0.1 for warmup experiments\n",
    "\n",
    "# LoRA Settings (keep fixed for this experiment)\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.05\n",
    "\n",
    "# Logging\n",
    "LOGGING_STEPS = 5       # Log every 5 steps for smooth curves\n",
    "\n",
    "# Output\n",
    "RUN_NAME = \"constant_lr\"  # Change for each run\n",
    "OUTPUT_DIR = f\"./outputs/{RUN_NAME}\"\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Model: {MODEL_ID}\")\n",
    "print(f\"   Dataset: {DATASET_ID}\")\n",
    "print(f\"   LR Schedule: {LR_SCHEDULE}\")\n",
    "print(f\"   Warmup: {WARMUP_RATIO*100}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-sEGm8DlZBc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Configuration loaded\n",
      "   Model: Qwen/Qwen2.5-0.5B-Instruct\n",
      "   Dataset: mlabonne/guanaco-llama2-1k\n",
      "   LR Schedule: constant\n",
      "   Warmup: 0.0%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5Ô∏è‚É£ Load Dataset\n",
    "\n",
    "The Guanaco dataset contains instruction-following conversations.\n",
    "\n",
    "Let's look at what the data looks like."
   ],
   "metadata": {
    "id": "JA2qcIDBlZBc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded: {len(dataset)} samples\")\n",
    "print(f\"\\nüìù Example:\")\n",
    "print(\"-\" * 50)\n",
    "print(dataset[0][\"text\"][:500] + \"...\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324,
     "referenced_widgets": [
      "e41452b26fcb4be79766389896091ec8",
      "5528b3841e594ba7871340e1778ff75c",
      "d67bede0ce054b94b84e0c6ac8f985c7",
      "9f8141f877584a08adda6837d379804d",
      "cc6301c4f39448148f23ddaae10118ed",
      "38dcb5612eb342f1aa37c24ea68212c6",
      "de144496f36a441b9f5fea7a1a8c293a",
      "2ac93e0bc448453cb87e4614de8d645d",
      "a25ff908626a47a8962c4bc2f6289958",
      "b4e9ed0d3edf4752b9b18e3d4f82311f",
      "b505f3b2dd584de8bbca8d73c47e613c",
      "6fe6621d9eda4fd1aa4395c1fe8d8faa",
      "b713d9ae409145f49a328788148dec3c",
      "eba84691ceb343c4a39ebf749bd813d6",
      "ee2269a848024419ad6a18a6158dc3e0",
      "a22e7d59652f4019969752d977c9d809",
      "589fb4908aef49e3beceb11f03f9985a",
      "f417c417d85641f6ba93a5acbb9ee2bb",
      "2675d3c2b24f47e9bf8e104be57decd0",
      "e916d2a54531470893f129d59e098ade",
      "6bf976649ac54999a7417eedf257c70f",
      "1a97bea8b7b14c229107562d41ea4406",
      "1f1cb43a2e7a4a97918e3db136b8c303",
      "23318726677d4de1bca0ec9b5db1fa1e",
      "81e8f5e66e38484181553b1cc323417f",
      "6cee94633d444755bc7d822921cae1d6",
      "3245001be9ff49bd97117a13f55d9710",
      "46d5b4cea30d4bc89555e9dd8d6591cc",
      "8df16369e345419ba672004aa77e3f39",
      "f15864f68f9b4a059f8a9647c79af937",
      "f94de9b92e534c6aaf80c6cbfde9a228",
      "b319715ffb6749b8b994f4859200e88b",
      "9fc6881aa16742e99aba0b2b3e86fde1"
     ]
    },
    "id": "sIaX3kd0lZBc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "data/train-00000-of-00001-9ad84bb9cf65a4(‚Ä¶):   0%|          | 0.00/967k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Dataset loaded: 1000 samples\n",
      "\n",
      "üìù Example:\n",
      "--------------------------------------------------\n",
      "<s>[INST] Me gradu√© hace poco de la carrera de medicina ¬øMe podr√≠as aconsejar para conseguir r√°pidamente un puesto de trabajo? [/INST] Esto vale tanto para m√©dicos como para cualquier otra profesi√≥n tras finalizar los estudios aniversarios y mi consejo ser√≠a preguntar a cu√°ntas personas haya conocido mejor. En este caso, mi primera opci√≥n ser√≠a hablar con otros profesionales m√©dicos, echar curr√≠culos en hospitales y cualquier centro de salud. En paralelo, trabajar√≠a por mejorar mi marca personal...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6Ô∏è‚É£ Load Model & Tokenizer\n",
    "\n",
    "We load in float16 to save VRAM."
   ],
   "metadata": {
    "id": "PgnzbvlslZBc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {MODEL_ID}\")\n",
    "print(f\"   Parameters: {model.num_parameters():,}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293,
     "referenced_widgets": [
      "c6fb462fdc9c41e6b8e2e0c53ed14727",
      "1f476fabe2f7487d882bbee9783ea994",
      "b100143e7c6b4f3a96cccb3242f2754b",
      "76e022baf3ca4bcd9abd3492ea6bf066",
      "ecb3a793a7484422a8de3cc449e41062",
      "04a50ef115134b15bb81faedbfdfd7d5",
      "27dcfc6c9c76417f986023080b3b136c",
      "8b3e4d333bb24d05898332c082ab2a92",
      "1bd822e3b38944c690b9bb496c8edb7d",
      "485238709a7e479f8b8dc54e4312c098",
      "12e9cd43096e48618b00d874e2f216c9",
      "9d59f2cd8af7435baae990fe8b23c893",
      "b11cb9484f0245e38e576d0a27499ca0",
      "7ab315abb9e440cdaaa85d814962ee81",
      "07a6c3b1bbbd46428a96a868002f2e36",
      "ef883be25bf9478080d53f5e5fe3131e",
      "2ad185055b9a44339424b86b9f1abcf0",
      "bb6860cc7a2349418a2b9c47ec16651a",
      "401c46c57a9b4420947eb3532c3cd4db",
      "c6582c196a7a47f5a5c9095d5e4da834",
      "d72b315bb7394d6da8deef42211f2a20",
      "2d2bf95d9f9a47a3827386459461df80",
      "932ecbc8746d442da08b8feabf5135ff",
      "dd8884dc0f274501aba3adcaf3266001",
      "bb1fe7000f924287ba4feadc00c6f4e9",
      "b6a1145515ac46cf88bd10005af6bbf5",
      "12b88679225340afa26b176b952f6656",
      "744514ef8f104afcbce460c0f0c1a5d9",
      "94f209d0b7664ce7be081dc6f7bb8c78",
      "d3b939d0ed064c79a738bccf4bbe0f6c",
      "224059a8edf345b483daf128e64f2c53",
      "bc916a87c8bc4062a8d756735d213bdf",
      "87e84c40328f4ebfb453743c9137d3cb",
      "38ffa0402e604a2ebe3b8294bdf24332",
      "1b5fbf8189bb428aa0f2ccf05cec3e76",
      "37f51036dc2e4b8885bccbf8d3093848",
      "3edbb7f6ca51456aa6d277991cb3a2ab",
      "3dc96f8779134f8e81e7f2e588ba8183",
      "ca9f204f266f4042a0ceb8cf70f1c5e0",
      "e00d8c3ba0314aa89eb37e5eeac62b98",
      "d6b4d0b53b7040eb88df040af0a51b8c",
      "b81644b3b1c44875bd32d4e0a6541121",
      "c7f519f4c5fd41888f6c315bcf08611f",
      "32e93022db784a8b936cca3e3d567bbd",
      "a3a87e450cf84b528397d32402a006e6",
      "97fa07eb2a58402abb1e7706e311c228",
      "3305f9ff32b14f649518ca24f2babcbf",
      "5121984f8c5b40079d4c6d439c67fb63",
      "dc769bf815824ebc9625aaaf1030df38",
      "400cfda38791436abb2d8abe11b4f737",
      "a1d9500322fa45a5a41e7e200d463dbd",
      "7d2ffdfbb36e4b04a8f2e3c991257274",
      "adf33dec9d1445a19344598e1a49c48b",
      "f2de32437625475887c6c01e08aa8acf",
      "d98ab8488ba24d4fb60fadf60aecb9a7",
      "8285a3bc55cf476491f728a3df59b711",
      "10061b56072d46df82c3f0c9ec763de9",
      "8eb4d8c5b62142e390eebd333a5b2fb9",
      "4344e06249df483b8ca77f924873752d",
      "8d422adba822492598aa7a3e9bc764d4",
      "ee9688373c0d455a91a3d95b95994a93",
      "60f0ad40441a4a31a91b3d6df1b8e190",
      "e140aee7d90c4178a0a7c4667ee533a2",
      "2ea6b895396440fdb954962a3a2d897e",
      "16f14a4e22a44e0dac05bac4fb607081",
      "dfe2d1e319a54bd3952bcd0bee10e8f0",
      "d6749239b04046c0af371e7aac805929",
      "99ec7b321d79414aa07e9826a24ca631",
      "e4fc2d6523a64d5189cffc6248e81ab7",
      "66901f85759e4cfa89129a774109229a",
      "9b259460f7ae44008c78985981846271",
      "7c2972e59b5a491281bddb79bce186d4",
      "5d83e5b06e5e437b9d0fd39461a80ff0",
      "6329af9a964a44c6bb18683233879bb3",
      "2894a612dea64ecca93aa893e2c6c354",
      "a62b7446f574475eb849d60017ecd27a",
      "1111635d35124c9086249bb17bb27c62"
     ]
    },
    "id": "FZjEuNSvlZBd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Model loaded: Qwen/Qwen2.5-0.5B-Instruct\n",
      "   Parameters: 494,032,768\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7Ô∏è‚É£ Apply LoRA\n",
    "\n",
    "Freeze the base model and add trainable adapter layers."
   ],
   "metadata": {
    "id": "N7LSSg-JlZBd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1rn6WBSlZBd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trainable params: 1,081,344 || all params: 495,114,112 || trainable%: 0.2184\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8Ô∏è‚É£ Training Arguments\n",
    "\n",
    "This is where we configure the learning rate schedule.\n",
    "\n",
    "### Understanding LR Schedules\n",
    "\n",
    "| Schedule | Behavior | When to use |\n",
    "|----------|----------|-------------|\n",
    "| `constant` | LR stays the same | Quick experiments |\n",
    "| `linear` | LR decreases linearly to 0 | Conservative training |\n",
    "| `cosine` | LR follows cosine curve to ~0 | Most common choice |\n",
    "\n",
    "**Warmup** gradually increases LR at the start to stabilize training."
   ],
   "metadata": {
    "id": "4_LSL0AYlZBd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\n",
    "    # Batch settings\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "\n",
    "    # Training length\n",
    "    max_steps=MAX_STEPS,\n",
    "\n",
    "    # Learning rate settings ‚≠ê\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lr_scheduler_type=LR_SCHEDULE,    # \"constant\", \"cosine\", \"linear\"\n",
    "    warmup_ratio=WARMUP_RATIO,        # 0.0 = no warmup, 0.1 = 10% warmup\n",
    "\n",
    "    # Precision\n",
    "    fp16=True,\n",
    "\n",
    "    # Logging ‚≠ê\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    report_to=\"wandb\",                # Send logs to W&B\n",
    "    run_name=RUN_NAME,                # Name in W&B dashboard\n",
    "\n",
    "    # Checkpoints (we'll cover this in Part 6)\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    # Misc\n",
    "    optim=\"adamw_torch\",\n",
    "    seed=42,                          # Reproducibility\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"   LR Schedule: {LR_SCHEDULE}\")\n",
    "print(f\"   Warmup: {WARMUP_RATIO*100}%\")\n",
    "print(f\"   Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5cbbOdBlZBd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Training arguments configured\n",
      "   LR Schedule: constant\n",
      "   Warmup: 0.0%\n",
      "   Effective batch size: 16\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9Ô∏è‚É£ Create Trainer"
   ],
   "metadata": {
    "id": "hNVJfELNlZBd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer ready\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "6b067e8cc43244e5a6e4f5b23a3807d4",
      "297f9f40cf684e2e9bb4f16aaeb748bd",
      "46731d8d528e4e9db3739966e802d96c",
      "6344bdd1d44345a284dabf3a3887e20c",
      "8ffb7b6508ab406fb5d67782a2cf5464",
      "8dbfe9305a1e4559bac6bcaed0b50fff",
      "5d7bac59deb14252b6cafaae332aa4c6",
      "4a7ae75efc0644d597e3f15a897908b9",
      "973ef43a44da4bb5aeaca2a7d92c1a7a",
      "b32f3730dd254d34b8eaec51d8b5ab8f",
      "5f3742b7bd544cfdb177d815bb06a350",
      "5a5e94f33eb14388b2fb7285806f4dcf",
      "3a0574ddf17248338c6b508f7c24b69f",
      "b0aecb5179144d0d8a8902e72fbdd69c",
      "20716be79ef64a78963e3f6ae5179612",
      "b7fdf742c67a429481db7143e22b0faa",
      "ee34b2b52b1b4a45ba627689c4da9a39",
      "48d0726ca58a41a2a97fa5c96c6c4bbe",
      "d3a8373339be4dfe8b43cc248b69915a",
      "c3bb10f96308447a8fecc067a1a156b1",
      "3aa1dc3898fc4d2d8195e7a5ae148d33",
      "93e34d871b2c477a9c24bea8a3383b4d",
      "ad0bb0829bd9407a96facc51e176972a",
      "acd56a26ba7b49d996e535e5d1de8ee9",
      "27f67e1345ef4a429c5e06e3f3b2d5aa",
      "215caf9950684ae2b1dd8a7bdab4af8c",
      "bd49b474645b4ac39521f8a28c86f0a2",
      "401526876b524fa795ecce36014d8252",
      "14583d296f0f4b8ab0a3fbeb94448646",
      "8af82f960b8c49558f8149600b7ffa36",
      "216a35443a4a439587d1782d8d9468e5",
      "a4f6c4800b25416ca5bec9b3df3ef8a8",
      "b2374ea942ab4a5f97c7a28d3a5f504c"
     ]
    },
    "id": "s8D-lxKwlZBe"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Trainer ready\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üîü Train!\n",
    "\n",
    "This will take ~10-15 minutes.\n",
    "\n",
    "**While training:**\n",
    "- Open your [W&B dashboard](https://wandb.ai) in another tab\n",
    "- Watch the loss curve update in real-time"
   ],
   "metadata": {
    "id": "CaL77tghlZBe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"üöÄ Starting training: {RUN_NAME}\")\n",
    "print(f\"   Watch live at: https://wandb.ai\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"‚úÖ Training complete: {RUN_NAME}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U0pAEvsVlZBe"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üöÄ Starting training: constant_lr\n",
      "   Watch live at: https://wandb.ai\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20260120_091119-4sjhzm2i</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/4sjhzm2i' target=\"_blank\">constant_lr</a></strong> to <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/4sjhzm2i' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/4sjhzm2i</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 08:41, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.781400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.708300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.678700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.713100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.641300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.593400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.726300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.643700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.677300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.680800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.645900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.802800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.631200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.561800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.586600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.704600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.734700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.576700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.603600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.706600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.589800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.678300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------\n",
      "‚úÖ Training complete: constant_lr\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Save the Adapter"
   ],
   "metadata": {
    "id": "ywCHbc3flZBe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(f\"‚úÖ Adapter saved to: {OUTPUT_DIR}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQssislOlZBe"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Adapter saved to: ./outputs/constant_lr\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Finish W&B Run"
   ],
   "metadata": {
    "id": "xkbqxRYolZBe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.finish()\n",
    "print(\"‚úÖ W&B run finished\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "AhHLXmaVlZBe"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/entropy</td><td>‚ñÑ‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÉ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÖ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÖ</td></tr><tr><td>train/mean_token_accuracy</td><td>‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñá‚ñá‚ñÉ‚ñá‚ñÜ</td></tr><tr><td>train/num_tokens</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3430423476632064.0</td></tr><tr><td>train/entropy</td><td>1.72361</td></tr><tr><td>train/epoch</td><td>3.176</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/grad_norm</td><td>0.45821</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.6783</td></tr><tr><td>train/mean_token_accuracy</td><td>0.62251</td></tr><tr><td>train/num_tokens</td><td>1171100.0</td></tr><tr><td>train_loss</td><td>1.67773</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">constant_lr</strong> at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/4sjhzm2i' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/4sjhzm2i</a><br> View project at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_091119-4sjhzm2i/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ W&B run finished\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# üî¨ Experiment Time!\n",
    "\n",
    "Now let's run the same training with different LR schedules and compare.\n",
    "\n",
    "## How to Run Multiple Experiments\n",
    "\n",
    "**Option A: Restart and modify**\n",
    "1. Go to `Runtime` ‚Üí `Restart runtime`\n",
    "2. Change `LR_SCHEDULE` and `RUN_NAME` in the config cell\n",
    "3. Run all cells again\n",
    "\n",
    "**Option B: Use the quick-run cell below**\n",
    "\n",
    "The cell below lets you run a new experiment without restarting."
   ],
   "metadata": {
    "id": "W9DPdZT8lZBe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# QUICK RUN: Change settings and run this cell\n",
    "# ============================================================\n",
    "\n",
    "def run_experiment(lr_schedule, warmup_ratio, run_name):\n",
    "    \"\"\"Run a training experiment with specified LR schedule.\"\"\"\n",
    "    import gc\n",
    "\n",
    "    # Clear memory from previous run\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Reload model fresh\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Starting experiment: {run_name}\")\n",
    "    print(f\"   LR Schedule: {lr_schedule}\")\n",
    "    print(f\"   Warmup: {warmup_ratio*100}%\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Load fresh model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    # Training args with new schedule\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"./outputs/{run_name}\",\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRAD_ACCUM,\n",
    "        max_steps=MAX_STEPS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        lr_scheduler_type=lr_schedule,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        fp16=True,\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=run_name,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        save_total_limit=2,\n",
    "        optim=\"adamw_torch\",\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=dataset,\n",
    "        processing_class=tokenizer,\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Save\n",
    "    trainer.model.save_pretrained(f\"./outputs/{run_name}\")\n",
    "\n",
    "    # Finish W&B\n",
    "    wandb.finish()\n",
    "\n",
    "    print(f\"\\n‚úÖ Experiment complete: {run_name}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del model, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"‚úÖ run_experiment() function ready\")\n",
    "print(\"\\nRun experiments with:\")\n",
    "print('  run_experiment(\"constant\", 0.0, \"exp1_constant\")')\n",
    "print('  run_experiment(\"cosine\", 0.0, \"exp2_cosine\")')\n",
    "print('  run_experiment(\"cosine\", 0.1, \"exp3_cosine_warmup\")')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-iUfdjplZBf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ run_experiment() function ready\n",
      "\n",
      "Run experiments with:\n",
      "  run_experiment(\"constant\", 0.0, \"exp1_constant\")\n",
      "  run_experiment(\"cosine\", 0.0, \"exp2_cosine\")\n",
      "  run_experiment(\"cosine\", 0.1, \"exp3_cosine_warmup\")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Experiment 1: Constant LR"
   ],
   "metadata": {
    "id": "s5WcgOUrlZBf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "run_experiment(\"constant\", 0.0, \"exp1_constant\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yu7bZ39alZBf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Starting experiment: exp1_constant\n",
      "   LR Schedule: constant\n",
      "   Warmup: 0.0%\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20260120_092515-60ypma3z</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/60ypma3z' target=\"_blank\">exp1_constant</a></strong> to <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/60ypma3z' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/60ypma3z</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 08:37, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.795600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.782300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.783100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.707400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.702300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.713300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.641500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.726500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.680400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.804300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.705200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.700400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.734300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.605400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.706500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.679800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/entropy</td><td>‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÜ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÖ</td></tr><tr><td>train/mean_token_accuracy</td><td>‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñá‚ñá‚ñÉ‚ñá‚ñÜ</td></tr><tr><td>train/num_tokens</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3430423476632064.0</td></tr><tr><td>train/entropy</td><td>1.72372</td></tr><tr><td>train/epoch</td><td>3.176</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/grad_norm</td><td>0.46342</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.6798</td></tr><tr><td>train/mean_token_accuracy</td><td>0.6206</td></tr><tr><td>train/num_tokens</td><td>1171100.0</td></tr><tr><td>train_loss</td><td>1.67819</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp1_constant</strong> at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/60ypma3z' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/60ypma3z</a><br> View project at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_092515-60ypma3z/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "‚úÖ Experiment complete: exp1_constant\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Experiment 2: Cosine Decay (no warmup)"
   ],
   "metadata": {
    "id": "PxnKUtTrlZBf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "run_experiment(\"cosine\", 0.0, \"exp2_cosine\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eSyHNFiclZBf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Starting experiment: exp2_cosine\n",
      "   LR Schedule: cosine\n",
      "   Warmup: 0.0%\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20260120_093407-b8o6lkxk</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/b8o6lkxk' target=\"_blank\">exp2_cosine</a></strong> to <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/b8o6lkxk' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/b8o6lkxk</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 07:48, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.801300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.795900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.783400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.722100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.622700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.713800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.596600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.729400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.668300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.680100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.658400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.603200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.634600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.599800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.670700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.721700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.717500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.673200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.749700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.591100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.613100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.634100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.726200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/entropy</td><td>‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ</td></tr><tr><td>train/learning_rate</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÜ</td></tr><tr><td>train/mean_token_accuracy</td><td>‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñá‚ñá‚ñÉ‚ñÜ‚ñÖ</td></tr><tr><td>train/num_tokens</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3430423476632064.0</td></tr><tr><td>train/entropy</td><td>1.79142</td></tr><tr><td>train/epoch</td><td>3.176</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/grad_norm</td><td>0.41368</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7262</td></tr><tr><td>train/mean_token_accuracy</td><td>0.61091</td></tr><tr><td>train/num_tokens</td><td>1171100.0</td></tr><tr><td>train_loss</td><td>1.68611</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp2_cosine</strong> at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/b8o6lkxk' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/b8o6lkxk</a><br> View project at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_093407-b8o6lkxk/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "‚úÖ Experiment complete: exp2_cosine\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Experiment 3: Cosine Decay + 10% Warmup"
   ],
   "metadata": {
    "id": "TbDmqrr2lZBf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "run_experiment(\"cosine\", 0.1, \"exp3_cosine_warmup\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-VpuctEslZBf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Starting experiment: exp3_cosine_warmup\n",
      "   LR Schedule: cosine\n",
      "   Warmup: 10.0%\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20260120_094206-0heg16h1</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/0heg16h1' target=\"_blank\">exp3_cosine_warmup</a></strong> to <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/0heg16h1' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/0heg16h1</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 07:47, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.825700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.879800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.857400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.832800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.733900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.631600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.709800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.764100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.715700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.645200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.651600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.652100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.811500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.637200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.575100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.671900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.722600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.718700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.674400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.718200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.751300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.591600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.634100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.726500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/entropy</td><td>‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>train/learning_rate</td><td>‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÖ</td></tr><tr><td>train/mean_token_accuracy</td><td>‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñà‚ñá‚ñá‚ñÑ‚ñÜ‚ñÖ</td></tr><tr><td>train/num_tokens</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3430423476632064.0</td></tr><tr><td>train/entropy</td><td>1.79131</td></tr><tr><td>train/epoch</td><td>3.176</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/grad_norm</td><td>0.4191</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7265</td></tr><tr><td>train/mean_token_accuracy</td><td>0.61057</td></tr><tr><td>train/num_tokens</td><td>1171100.0</td></tr><tr><td>train_loss</td><td>1.69734</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp3_cosine_warmup</strong> at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/0heg16h1' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface/runs/0heg16h1</a><br> View project at: <a href='https://wandb.ai/balci-pelin-patolojiai/huggingface' target=\"_blank\">https://wandb.ai/balci-pelin-patolojiai/huggingface</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_094206-0heg16h1/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "‚úÖ Experiment complete: exp3_cosine_warmup\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# üìä Analyzing Results\n",
    "\n",
    "## In W&B Dashboard\n",
    "\n",
    "1. Go to [wandb.ai](https://wandb.ai) ‚Üí Your project\n",
    "2. Click on a run to see its metrics\n",
    "3. To compare runs:\n",
    "   - Select multiple runs (checkboxes)\n",
    "   - Click \"Add to comparison\"\n",
    "   - View overlaid loss curves\n",
    "\n",
    "## What to Look For\n",
    "\n",
    "### Loss Curve Shapes\n",
    "\n",
    "```\n",
    "Good training:          Overfitting:            Unstable:\n",
    "                        \n",
    "Loss                    Loss                    Loss\n",
    "  ‚îÇ‚ï≤                      ‚îÇ‚ï≤                      ‚îÇ‚ï≤  /‚ï≤\n",
    "  ‚îÇ ‚ï≤                     ‚îÇ ‚ï≤___                  ‚îÇ ‚ï≤/  ‚ï≤/‚ï≤\n",
    "  ‚îÇ  ‚ï≤___                 ‚îÇ     ‚ï≤__/‚îÄ‚îÄ            ‚îÇ       ‚ï≤/\n",
    "  ‚îÇ      ‚ï≤___             ‚îÇ                       ‚îÇ\n",
    "  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  Smooth decrease         Goes up = overfit       Spiky = LR too high\n",
    "```\n",
    "\n",
    "### Comparing LR Schedules\n",
    "\n",
    "| Schedule | Expected behavior |\n",
    "|----------|------------------|\n",
    "| Constant | Steady decrease, might plateau |\n",
    "| Cosine | Faster early, slows down nicely |\n",
    "| Cosine + Warmup | Slower start, then smooth curve |"
   ],
   "metadata": {
    "id": "Lx1ubHl5lZBg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# üß† Key Takeaways\n",
    "\n",
    "## 1. Loss Tells You If Training Works\n",
    "- **Decreasing loss** = model is learning\n",
    "- **Flat loss** = learning rate too low, or model saturated\n",
    "- **Increasing loss** = learning rate too high, or overfitting\n",
    "- **Spiky loss** = batch too small, or LR too high\n",
    "\n",
    "## 2. LR Schedule Matters\n",
    "- **Constant**: Simple, but may not converge well\n",
    "- **Cosine**: Usually best default choice\n",
    "- **Warmup**: Helps with large models or unstable starts\n",
    "\n",
    "## 3. Effective Batch Size = Stability\n",
    "- Larger effective batch ‚Üí smoother gradients ‚Üí more stable training\n",
    "- We used: `batch_size=2 √ó grad_accum=8 = 16`\n",
    "\n",
    "## 4. Logging Frequency Matters\n",
    "- Too infrequent ‚Üí miss important dynamics\n",
    "- Too frequent ‚Üí noisy curves\n",
    "- `logging_steps=5` is a good balance\n",
    "\n",
    "---\n",
    "\n",
    "## Next: Part 4 - Hyperparameter Impact\n",
    "\n",
    "We'll experiment with:\n",
    "- LoRA rank (r): 4 vs 8 vs 16 vs 32\n",
    "- Target modules: QV only vs QKVO vs +MLP\n",
    "- Learning rate: 1e-4 vs 2e-4 vs 5e-4\n",
    "\n",
    "And use evaluation methods to compare which settings work best!"
   ],
   "metadata": {
    "id": "TfK4zehylZBg"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![image](Part3_LR_Experiment.PNG)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All three achieved similar final loss (~1.6-1.8) and accuracy (~61%). The warmup schedule showed smoother gradient norms at the start, but didn't dramatically improve final performance."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
